{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改预训练模型的缓存目录\n",
    "import os\n",
    "\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = r\"G:\\code\\pretrain_model_dir\\_modelscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 21:03:35,603 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
      "2024-03-28 21:03:35,606 - modelscope - INFO - TensorFlow version 2.8.0 Found.\n",
      "2024-03-28 21:03:35,606 - modelscope - INFO - Loading ast index from G:\\code\\pretrain_model_dir\\_modelscope\\ast_indexer\n",
      "2024-03-28 21:03:35,989 - modelscope - INFO - Loading done! Current index file version is 1.12.0, with md5 ba00b7358e147b49b70e6555c5c8ccf2 and a total number of 964 components indexed\n",
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 594/594 [00:00<00:00, 79.1kB/s]\n",
      "Downloading: 100%|██████████| 73.0/73.0 [00:00<00:00, 9.48kB/s]\n",
      "Downloading: 100%|██████████| 181/181 [00:00<00:00, 24.0kB/s]\n",
      "Downloading: 100%|█████████▉| 9.28G/9.28G [05:49<00:00, 28.5MB/s]\n",
      "Downloading: 100%|█████████▉| 3.59G/3.59G [02:16<00:00, 28.2MB/s]\n",
      "Downloading: 100%|██████████| 21.9k/21.9k [00:00<00:00, 602kB/s]\n",
      "Downloading: 100%|██████████| 3.16k/3.16k [00:00<00:00, 400kB/s]\n",
      "Downloading: 100%|██████████| 4.40M/4.40M [00:00<00:00, 6.66MB/s]\n",
      "Downloading: 100%|██████████| 1.25k/1.25k [00:00<00:00, 186kB/s]\n"
     ]
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('deepseek-ai/deepseek-llm-7b-chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 21:30:48,543 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
      "2024-03-28 21:30:48,547 - modelscope - INFO - TensorFlow version 2.8.0 Found.\n",
      "2024-03-28 21:30:48,547 - modelscope - INFO - Loading ast index from G:\\code\\pretrain_model_dir\\_modelscope\\ast_indexer\n",
      "2024-03-28 21:30:48,735 - modelscope - INFO - Loading done! Current index file version is 1.12.0, with md5 ba00b7358e147b49b70e6555c5c8ccf2 and a total number of 964 components indexed\n",
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是DeepSeek Chat，一个智能AI机器人，能够通过自然语言进行交流和对话，帮助用户回答问题、提供建议、提供娱乐等。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "# model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "model_name = r\"G:\\code\\pretrain_model_dir\\_modelscope\\deepseek-ai\\deepseek-llm-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"你是谁?\"}\n",
    "]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=100)\n",
    "\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='G:\\code\\pretrain_model_dir\\_modelscope\\deepseek-ai\\deepseek-llm-7b-chat', vocab_size=100000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t100000: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t100001: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t100002: AddedToken(\"ø\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100003: AddedToken(\"ö\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100004: AddedToken(\"ú\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100005: AddedToken(\"ÿ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100006: AddedToken(\"õ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100007: AddedToken(\"÷\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100008: AddedToken(\"û\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100009: AddedToken(\"ý\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100010: AddedToken(\"À\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100011: AddedToken(\"ù\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100012: AddedToken(\"Á\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100013: AddedToken(\"þ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100014: AddedToken(\"ü\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./vocab\\\\tokenizer_config.json',\n",
       " './vocab\\\\special_tokens_map.json',\n",
       " './vocab\\\\tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='G:\\code\\pretrain_model_dir\\_modelscope\\deepseek-ai\\deepseek-llm-7b-chat', vocab_size=100000, model_max_length=4096, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t100000: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t100001: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t100002: AddedToken(\"ø\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100003: AddedToken(\"ö\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100004: AddedToken(\"ú\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100005: AddedToken(\"ÿ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100006: AddedToken(\"õ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100007: AddedToken(\"÷\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100008: AddedToken(\"û\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100009: AddedToken(\"ý\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100010: AddedToken(\"À\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100011: AddedToken(\"ù\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100012: AddedToken(\"Á\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100013: AddedToken(\"þ\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t100014: AddedToken(\"ü\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
