{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改预训练模型的缓存目录\n",
    "import os\n",
    "\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = r\"G:\\code\\pretrain_model_dir\\_modelscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 14:06:24,903 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
      "2023-12-17 14:06:24,906 - modelscope - INFO - TensorFlow version 2.8.0 Found.\n",
      "2023-12-17 14:06:24,906 - modelscope - INFO - Loading ast index from G:\\code\\pretrain_model_dir\\_modelscope\\ast_indexer\n",
      "2023-12-17 14:06:25,157 - modelscope - INFO - Loading done! Current index file version is 1.9.4, with md5 bfb2e3fa67418cb37742cf2ad665ce75 and a total number of 945 components indexed\n",
      "2023-12-17 14:06:25,490 - modelscope - WARNING - Using the master branch is fragile, please use it with caution!\n",
      "2023-12-17 14:06:25,491 - modelscope - INFO - Use user-specified model revision: master\n",
      "Downloading: 100%|██████████| 86.0/86.0 [00:00<00:00, 14.1kB/s]\n",
      "Downloading: 100%|██████████| 841/841 [00:00<00:00, 163kB/s]\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 9.55kB/s]\n",
      "Downloading: 100%|██████████| 8.07k/8.07k [00:00<00:00, 1.58MB/s]\n",
      "Downloading: 100%|██████████| 132/132 [00:00<00:00, 28.4kB/s]\n",
      "Downloading: 100%|██████████| 3.78k/3.78k [00:00<00:00, 255kB/s]\n",
      "Downloading: 100%|██████████| 44.3k/44.3k [00:00<00:00, 610kB/s]\n",
      "Downloading: 100%|█████████▉| 1.81G/1.81G [01:08<00:00, 28.5MB/s]\n",
      "Downloading: 100%|█████████▉| 1.80G/1.80G [01:09<00:00, 28.0MB/s]\n",
      "Downloading: 100%|█████████▉| 1.80G/1.80G [01:07<00:00, 28.5MB/s]\n",
      "Downloading: 100%|█████████▉| 1.85G/1.85G [01:09<00:00, 28.8MB/s]\n",
      "Downloading: 100%|█████████▉| 1.85G/1.85G [01:10<00:00, 28.3MB/s]\n",
      "Downloading: 100%|█████████▉| 1.85G/1.85G [01:10<00:00, 28.3MB/s]\n",
      "Downloading: 100%|█████████▉| 1.85G/1.85G [01:14<00:00, 26.9MB/s]\n",
      "Downloading: 100%|█████████▉| 782M/782M [00:28<00:00, 28.6MB/s]\n",
      "Downloading: 100%|██████████| 23.5k/23.5k [00:00<00:00, 530kB/s]\n",
      "Downloading: 100%|██████████| 5.90k/5.90k [00:00<00:00, 360kB/s]\n",
      "Downloading: 100%|██████████| 644/644 [00:00<00:00, 73.9kB/s]\n",
      "Downloading: 100%|██████████| 9.40k/9.40k [00:00<00:00, 1.37MB/s]\n",
      "Downloading: 100%|██████████| 1.54M/1.54M [00:00<00:00, 4.77MB/s]\n",
      "Downloading: 100%|██████████| 960/960 [00:00<00:00, 104kB/s]\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"vivo-ai/BlueLM-7B-Chat-32K\", revision=\"master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:10:00,125 - modelscope - INFO - PyTorch version 2.1.0+cu121 Found.\n",
      "2023-12-17 18:10:00,128 - modelscope - INFO - TensorFlow version 2.8.0 Found.\n",
      "2023-12-17 18:10:00,128 - modelscope - INFO - Loading ast index from G:\\code\\pretrain_model_dir\\_modelscope\\ast_indexer\n",
      "2023-12-17 18:10:00,350 - modelscope - INFO - Loading done! Current index file version is 1.9.4, with md5 bfb2e3fa67418cb37742cf2ad665ce75 and a total number of 945 components indexed\n",
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-17 18:10:09,596 - modelscope - WARNING - Using the master branch is fragile, please use it with caution!\n",
      "2023-12-17 18:10:09,596 - modelscope - INFO - Use user-specified model revision: master\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:21<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三国演义的作者是谁？ 《三国演义》的作者是明代小说家罗贯中。\n"
     ]
    }
   ],
   "source": [
    "# 使用扩展的 32k 版本, 需要安装 flash_attn 2.3 以上的版本\n",
    "import torch\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer, snapshot_download\n",
    "model_dir = snapshot_download(\"vivo-ai/BlueLM-7B-Chat-32K\", revision=\"master\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"cuda:0\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model = model.eval()\n",
    "inputs = tokenizer(\"[|Human|]:三国演义的作者是谁？[|AI|]:\", return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cuda:0\")\n",
    "pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)\n",
    "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金子为什么浮在水面上 金子的密度比水大，因此会沉在水的下面。如果将金子做成一个空心的小球，那么这个小球就会浮在水面上。这是因为金子的重量超过了它的体积，而空心的结构使得它的重量减小了。\n"
     ]
    }
   ],
   "source": [
    "# 应该是当前第一个回答对这个问题的本地模型了, 在线模型试过 bing 是可以回答对的.\n",
    "inputs = tokenizer(\"[|Human|]:金子为什么浮在水面上[|AI|]:\", return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cuda:0\")\n",
    "pred = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1)\n",
    "print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: flash-attn\n",
      "Version: 2.3.6\n",
      "Summary: Flash Attention: Fast and Memory-Efficient Exact Attention\n",
      "Home-page: https://github.com/Dao-AILab/flash-attention\n",
      "Author: Tri Dao\n",
      "Author-email: trid@cs.stanford.edu\n",
      "License: UNKNOWN\n",
      "Location: c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages\n",
      "Requires: einops, ninja, packaging, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.1.0+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, auto-gptq, bert-score, flair, flash-attn, lion-pytorch, optimum, peft, pytorch-lightning, pytorch_revgrad, torchmetrics, torchvision, transformer-smaller-training-vocab, xformers\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
