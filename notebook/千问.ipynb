{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TOC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: transformers_stream_generator\n"
     ]
    }
   ],
   "source": [
    "!pip show transformers_stream_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple\n",
      "Collecting transformers_stream_generator\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/36/26/3492ab0e45d814533b34ca605f8a20fdc032736f937679c6f212d81a76a5/transformers-stream-generator-0.0.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers>=4.26.1 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers_stream_generator) (4.27.4)\n",
      "Requirement already satisfied: filelock in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2021.11.10)\n",
      "Requirement already satisfied: requests in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.27.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.26.1->transformers_stream_generator) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.26.1->transformers_stream_generator) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from packaging>=20.0->transformers>=4.26.1->transformers_stream_generator) (3.0.6)\n",
      "Requirement already satisfied: colorama in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm>=4.27->transformers>=4.26.1->transformers_stream_generator) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.3)\n",
      "Building wheels for collected packages: transformers_stream_generator\n",
      "  Building wheel for transformers_stream_generator (setup.py): started\n",
      "  Building wheel for transformers_stream_generator (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12335 sha256=832faffdcac96732648b80e1cf761bb23de876beb60c6e0cb8994a55caf3542e\n",
      "  Stored in directory: c:\\users\\zhenh\\appdata\\local\\pip\\cache\\wheels\\42\\b9\\ba\\8a48b1e1d6aa50d794c0f095bfa576920f06eaa561d3dd74f9\n",
      "Successfully built transformers_stream_generator\n",
      "Installing collected packages: transformers_stream_generator\n",
      "Successfully installed transformers_stream_generator-0.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers_stream_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flair 0.12.1 requires huggingface-hub==0.10.0, but you have huggingface-hub 0.16.4 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/09/69/160de19b7846923d5e1357a9a61036228806fb2ba726bdd8ee930cbd4bf4/tiktoken-0.4.0-cp38-cp38-win_amd64.whl (635 kB)\n",
      "     -------------------------------------- 635.3/635.3 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading https://mirrors.tuna.tsinghua.edu.cn/pypi/web/packages/26/7e/69ea9212922e7b5150e81ba9fdd1981267ed9924b1c40fd38febb001585f/regex-2023.8.8-cp38-cp38-win_amd64.whl (268 kB)\n",
      "     ---------------------------------------- 268.3/268.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from tiktoken) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Installing collected packages: regex, tiktoken\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2021.11.10\n",
      "    Uninstalling regex-2021.11.10:\n",
      "      Successfully uninstalled regex-2021.11.10\n",
      "Successfully installed regex-2023.8.8 tiktoken-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改预训练模型的缓存目录\n",
    "import os\n",
    "\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = r\"G:\\code\\pretrain_model_dir\\_modelscope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tech\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-20 21:19:45,214 - modelscope - INFO - PyTorch version 1.13.1+cu117 Found.\n",
      "2023-08-20 21:19:45,216 - modelscope - INFO - TensorFlow version 2.8.0 Found.\n",
      "2023-08-20 21:19:45,216 - modelscope - INFO - Loading ast index from G:\\code\\pretrain_model_dir\\_modelscope\\ast_indexer\n",
      "2023-08-20 21:19:45,286 - modelscope - INFO - Loading done! Current index file version is 1.8.3, with md5 f01211d2b2e03771df6500e25770738b and a total number of 895 components indexed\n",
      "2023-08-20 21:19:46,220 - modelscope - INFO - Use user-specified model revision: v1.0.5\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "2023-08-20 21:19:47,099 - modelscope - INFO - Use user-specified model revision: v1.0.5\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n",
      "2023-08-20 21:19:58,756 - modelscope - INFO - Use user-specified model revision: v1.0.5\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',device_map=\"auto\", trust_remote_code=True,fp16 = True).eval()\n",
    "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-7B-Chat\",revision = 'v1.0.5', trust_remote_code=True) # 可指定不同的生成长度、top_p等相关超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接装没成功, 以前有个编译好的, 直接拿来用了\n",
    "!pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: flash-attn\n",
      "Version: 1.0.5\n",
      "Summary: Flash Attention: Fast and Memory-Efficient Exact Attention\n",
      "Home-page: https://github.com/HazyResearch/flash-attention\n",
      "Author: Tri Dao\n",
      "Author-email: trid@stanford.edu\n",
      "License: UNKNOWN\n",
      "Location: c:\\tech\\anaconda3\\envs\\nlp\\lib\\site-packages\n",
      "Requires: einops, ninja, packaging, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮忙的吗？\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哆啦A梦（日文：ドラえもん）是一部非常受欢迎的日本漫画和动画作品，由藤子·F·不二雄（原名：藤本弘）创作。它讲述了一个名为野比大雄的男孩的故事，他被一只蓝色的猫型机器人叫做哆啦A梦带到了未来世界，帮助他解决各种问题和冒险。哆啦A梦还有一只非常可爱的伙伴，一只小熊型机器人叫做小叮当。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"哆啦A梦是\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的！我很乐意扮演你的哆啦A梦。请问有什么问题我可以帮忙解决吗？\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"我是大雄, 你要扮演我的哆啦A梦, 请说你准备好了\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "啊，这可怎么办？宇宙毁灭了可就太糟糕了！不过别担心，我可以帮助你。首先，我们可以通过制造一个时空机器来回到过去，这样你就可以重新开始并成功娶到静香了。其次，我们还可以寻找一种可以拯救宇宙的方法，比如说找到一颗可以抵消毁灭力量的星球或者找到一种可以抵抗毁灭力量的力量。不过，这些都需要耗费大量的时间和精力，可能需要你的帮助才能完成。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"不好了, 不好了, 宇宙要毁灭了, 我还没娶到静香\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你想要在静香高中时期向她表白，那么你可以考虑使用一些浪漫的道具来制造惊喜。例如，你可以制作一本写满你对她的爱意的日记，或者在她的教室里放飞一只彩色的气球，上面写着你的名字和你想对她说的话。你还可以为她准备一份特别的礼物，比如一条手链或者一张手绘的明信片，上面写满了你对她的祝福和爱意。最后，你可以准备一个浪漫的晚餐，比如在她最喜欢的餐厅里安排一顿精致的晚餐，然后在晚餐中向她表白。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"哈哈, 我回到了静香高中的时候, 我要怎么和她表白, 给我一些能制造浪漫的道具\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果静香不认识穿越回去的你，那么你可能需要重新考虑一下你的表白方式。你可以试着重新介绍自己，让她了解你是一个怎样的人，你有什么优点和独特之处。此外，你也可以尝试重新了解她，了解她的兴趣爱好和性格特点，以便更好地打动她。最后，你还可以尝试制造更多的浪漫和惊喜，比如给她送一份特别的礼物，或者安排一个特别的活动，让她度过一个难忘的时光。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"完了, 我被静香拒绝了, 她不认识穿越回去的我了, 怎么办\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果你想要和静香分享一些你和她之间的故事，那么你可以考虑讲述一些有趣的经历或者回忆。例如，你可以讲述你们一起度过的快乐时光，比如去公园散步、看电影、或者参加聚会。你也可以讲述一些难忘的瞬间，比如一起庆祝生日或者度过的第一个情人节。此外，你还可以讲述一些你和静香之间的默契，比如你们都喜欢同样的音乐、电影或者书籍，或者你们之间有很多共同的话题。最后，你还可以讲述一些你对静香的感受和爱意，比如你为什么喜欢她、你对她的感觉和期望等等。\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"有哪些我和静香的故事可以用, 多讲一些, 我好和她说说\", history=history) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
